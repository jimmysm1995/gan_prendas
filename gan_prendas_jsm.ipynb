{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# GAN para generar prendas de vestir\n",
    "\n",
    "# En este notebook se implementa una GAN para generar prendas de vestir. La idea es que la GAN aprenda a generar imágenes de prendas de vestir a partir de un conjunto de datos de imágenes de prendas de vestir reales."
   ],
   "id": "2e7d4e6d2e6db20e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importar librerías",
   "id": "1cbef3d145dc0893"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-05T11:32:02.922622Z",
     "start_time": "2025-02-05T11:32:02.911494Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape, Conv2D, Conv2DTranspose, LeakyReLU, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Cargar datos",
   "id": "50855ebf009fbbf5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T11:32:06.264607Z",
     "start_time": "2025-02-05T11:32:05.562436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cargar Fashion MNIST\n",
    "(train_images, _), (_, _) = tf.keras.datasets.fashion_mnist.load_data()"
   ],
   "id": "cdcd6500336959a5",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T11:32:07.449613Z",
     "start_time": "2025-02-05T11:32:07.439051Z"
    }
   },
   "cell_type": "code",
   "source": "train_images.shape",
   "id": "5a097ae4f2e97bd4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Normalizar imágenes",
   "id": "5ca005aa8a3412f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T11:32:10.126081Z",
     "start_time": "2025-02-05T11:32:09.878576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5"
   ],
   "id": "7623026a8a2358df",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Definimos las Constantes",
   "id": "a299bb53def28d12"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T11:32:11.749711Z",
     "start_time": "2025-02-05T11:32:11.744693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "NUMBER_OF_IMAGES = 60000\n",
    "BATCH_SIZE = 256"
   ],
   "id": "6c7b397e1f52ff7e",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "619b4845df4fcb3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T11:31:04.852837Z",
     "start_time": "2025-02-05T11:31:04.435566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Crear dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(NUMBER_OF_IMAGES).batch(BATCH_SIZE)"
   ],
   "id": "de26ff295c2a1ddd",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T11:32:20.459324Z",
     "start_time": "2025-02-05T11:32:20.453181Z"
    }
   },
   "cell_type": "code",
   "source": "train_dataset",
   "id": "b61c2380d909e8e2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=None)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Definimos el Generador",
   "id": "cc0fd5edcd85b948"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T11:32:22.813408Z",
     "start_time": "2025-02-05T11:32:22.713360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_generator():\n",
    "    model = Sequential([\n",
    "        Dense(7 * 7 * 256, use_bias=False, input_shape=(100,)),\n",
    "        LeakyReLU(),\n",
    "        Reshape((7, 7, 256)),  # Imagen inicial pequeña\n",
    "\n",
    "        Conv2DTranspose(128, (5, 5), strides=(1, 1), padding=\"same\", use_bias=False),\n",
    "        LeakyReLU(),\n",
    "\n",
    "        Conv2DTranspose(64, (5, 5), strides=(2, 2), padding=\"same\", use_bias=False),\n",
    "        LeakyReLU(),\n",
    "\n",
    "        Conv2DTranspose(1, (5, 5), strides=(2, 2), padding=\"same\", use_bias=False, activation=\"tanh\")  \n",
    "    ])\n",
    "    return model\n",
    "\n",
    "generator = build_generator()\n"
   ],
   "id": "d02059471ab71b5b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\j.b.sanchez.martinez\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Definimos el Discriminador",
   "id": "975bff3ab207f5cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T11:33:23.408889Z",
     "start_time": "2025-02-05T11:33:23.355326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_discriminator():\n",
    "    model = Sequential([\n",
    "        Conv2D(64, (5, 5), strides=(2, 2), padding=\"same\", input_shape=(28, 28, 1)),\n",
    "        LeakyReLU(),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Conv2D(128, (5, 5), strides=(2, 2), padding=\"same\"),\n",
    "        LeakyReLU(),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(1, activation=\"sigmoid\")  # Salida 0 (falso) o 1 (real)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "discriminator = build_discriminator()\n"
   ],
   "id": "722cfc42cac96f7e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\j.b.sanchez.martinez\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Definimos la función de pérdida y los optimizadores",
   "id": "6d6cf6c223611b70"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T11:33:28.912218Z",
     "start_time": "2025-02-05T11:33:28.900202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    return real_loss + fake_loss\n",
    "\n",
    "generator_optimizer = Adam(1e-4)\n",
    "discriminator_optimizer = Adam(1e-4)\n"
   ],
   "id": "c5eb8b000f180af",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Entrenamiento de la GAN",
   "id": "47d392775a5a598"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-02-05T11:33:46.309464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# Ruido fijo para visualizar resultados\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
    "\n",
    "# Función de entrenamiento\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_gen = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_disc = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_gen, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_disc, discriminator.trainable_variables))\n",
    "\n",
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        for image_batch in dataset:\n",
    "            train_step(image_batch)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            generate_and_save_images(generator, epoch + 1, seed)\n",
    "\n",
    "# Función para visualizar imágenes generadas\n",
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    predictions = model(test_input, training=False)\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.savefig(f\"image_at_epoch_{epoch}.png\")\n",
    "    plt.show()\n",
    "\n",
    "# Entrenar la GAN\n",
    "train(train_dataset, EPOCHS)"
   ],
   "id": "9f96cec9dd77520d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\j.b.sanchez.martinez\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:707: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x400 with 16 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Guardamos el modelo",
   "id": "ba90e13bc77a015"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "generator.save(\"generator.h5\")\n",
    "discriminator.save(\"discriminator.h5\")"
   ],
   "id": "c5284ff24b72a13"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d5b5b9b1c265847c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
